#!/bin/bash

#############################################################
##
##  B L A C K B A L S A M
##
##  https://github.com/stevencox/blackbalsam
##
##  A multi modal data science environment featuring
##    User Experience: Jupyter Notebooks
##    Visualization: Plotly, Bokeh, Leaflet, Yellowbrick, Seaborn,...
##    Compute: CPU / GPU / Apache Spark
##    Storage: NFS / Minio & S3 / Alluxio
## 
#############################################################
set -e #x

DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null 2>&1 && pwd )"
BLACKBALSAM_HOME=$( dirname $DIR )

export RELEASE=blackbalsam
export NAMESPACE=blackbalsam
export JHUB_VERSION=0.8.2
export DIST=$BLACKBALSAM_HOME/bin
export ETC=$BLACKBALSAM_HOME/etc
export PATH=$DIST/darwin-amd64:$PATH
# TODO: This is OSX specific. Fix.
export helm_dist=helm-v2.16.3-darwin-amd64.tar.gz
export helm_url=https://get.helm.sh/$helm_dist

#############################################################
##
##  Utilities:
##    Make namespace: Initialize the namespace.
##    Set YAML value
##    Generate secrets
##
#############################################################
kc () {
    kubectl --namespace $NAMESPACE $*
}
make_namespace () {
    if [ "$(kubectl get namespaces | grep -c $NAMESPACE)" == 0 ]; then
        kubectl create namespace $NAMESPACE
    fi
}
yaml_set_val () {
    yaml-set \
	--change="$1" \
        --value=$2 \
        -F dquote \
        $3
}
secrets () {
    secret_name=blackbalsam-secrets
    secret_config=$ETC/secrets/secrets.yaml
    query="{.items[?(@.metadata.name=='"$secret_name"')].metadata.name}"
    secret_exists=$(kc get secrets -o=jsonpath="$query" | grep -c $secret_name || true)
    up () {
	if [ "$secret_exists" -eq 0 ]; then
	    cp $secret_config.template $secret_config
	    yaml_set_val stringData.jupyterhub_secret_token $jupyterhub_secret_token $secret_config
	    yaml_set_val stringData.github_client_secret $github_client_secret $secret_config
	    yaml_set_val stringData.minio_access_key $minio_access_key $secret_config
	    yaml_set_val stringData.minio_secret_key $minio_secret_key $secret_config
	    yaml_set_val stringData.neo4j_password $neo4j_password $secret_config
	    kc apply -f $secret_config
	fi
    }
    down () {
	if [ "$secret_exists" -eq 0 ]; then
	    echo no secrets found
	else
	    kc delete -f $secret_config
	fi
    }
    status () {
	if [ "$secret_exists" -eq 0 ]; then
	    echo no secrets found
	else
	    kc get secrets/$secret_name -o=yaml
	fi
    }
    $*
}
#############################################################
##
##  Manage JupyterHub.
##
#############################################################
hub () {
    conf () {
        mkdir -p $DIST
        wget --timestamping --quiet --directory-prefix=$DIST $helm_url
        if [ ! -d $DIST/darwin-amd64 ]; then
            pushd $DIST
            tar xvzf $helm_dist
            popd
        fi
        if [ "$(kubectl get serviceaccount -n kube-system tiller -o yaml | grep -c tiller)" == 0 ]; then
            kubectl --namespace kube-system create serviceaccount tiller
            kubectl create clusterrolebinding tiller --clusterrole cluster-admin --serviceaccount=kube-system:tiller
            helm init --service-account tiller --history-max 100 --wait
            kubectl patch \
		    deployment \
		    tiller-deploy \
                    --namespace=kube-system --type=json \
                    --patch='[{"op": "add", "path": "/spec/template/spec/containers/0/command", "value": ["/tiller", "--listen=localhost:44134"]}]'
            helm version
            helm repo add jupyterhub https://jupyterhub.github.io/helm-chart/
            helm repo update
        fi
    }
    jupyterhub_ready () {
        kubectl get deployments \
                --namespace=$NAMESPACE \
                --selector app=jupyterhub,component=hub \
                -o=jsonpath="{.items[?(@.metadata.labels.component=='hub')].status.readyReplicas}"
    }
    wait () {
        while [[ ! "$(jupyterhub_ready)" == 1 ]]; do
            echo waiting
        done
    }
    up () {
	echo installing jupyterhub
        conf
        helm version
	pvc
        cp $ETC/hub/config.yaml.template config.yaml
	yaml_set_val auth.github.clientId $github_client_id config.yaml
	yaml_set_val auth.github.clientSecret $github_client_secret config.yaml
	yaml_set_val auth.github.callbackUrl $github_oauth_callback config.yaml
	yaml_set_val proxy.secretToken $jupyterhub_secret_token config.yaml
	yaml_set_val hub.baseUrl $jupyterhub_baseUrl config.yaml
	
        helm upgrade --install $RELEASE jupyterhub/jupyterhub \
             --namespace $NAMESPACE  \
             --version=$JHUB_VERSION \
             --values config.yaml
        proxy
        patch
    }
    pvc () {
	echo check for persistent volume claim...
	set +e
	pvc_exists=$(kubectl --namespace=$NAMESPACE get pvc | grep -c jhub-nfs-pvc)
	if [ "$pvc_exists" == 0 ]; then
	    echo install persistent volume claim...
	    kubectl --namespace=$NAMESPACE apply -f $ETC/pvc/
	fi
	set -e
    }	
    proxy () {
	if [ "$(kubectl get mapping | grep -c jupyter)" -eq 0 ]; then
            kubectl apply \
                    -f $ETC/ambassador/jupyterhub-ambassador-mapping.yaml \
                    --namespace=$NAMESPACE
	fi
    }
    patch () {
        # https://github.com/jupyterhub/kubespawner/issues/354        
        kubectl patch deploy \
                --namespace $NAMESPACE hub \
                --type json \
                --patch '[{"op": "replace", "path": "/spec/template/spec/containers/0/command", "value": ["bash", "-c", "\nmkdir -p ~/hotfix\ncp -r /usr/local/lib/python3.6/dist-packages/kubespawner ~/hotfix\nls -R ~/hotfix\npatch ~/hotfix/kubespawner/spawner.py << EOT\n72c72\n<             key=lambda x: x.last_timestamp,\n---\n>             key=lambda x: x.last_timestamp and x.last_timestamp.timestamp() or 0.,\nEOT\n\nPYTHONPATH=$HOME/hotfix jupyterhub --config /srv/jupyterhub_config.py --upgrade-db\n"]}]'

    }
    down () {
	echo uninstalling jupyterhub
        helm version
        if [[ "$(helm ls | grep -v NAME | grep -c jupyterhub)" -gt 0 ]]; then
            echo deleting helm release $RELEASE
            helm delete $RELEASE --purge
        fi
	#kubectl --namespace=$NAMESPACE delete -f $ETC/pvc/
    }
    restart () {
        down
        up
    }
    $*
}
#############################################################
##
##  Manage the software defined reverse proxy.
##
#############################################################
proxy () {
    up () {
	echo installing ambassador...
        helm repo add datawire https://www.getambassador.io
        helm install --name ambassador --namespace $NAMESPACE --set service.loadBalancerIP=$public_ip datawire/ambassador 
    }
    down () {
	echo uninstalling ambassador...
        if [[ "$(helm ls | grep -v NAME | grep -c ambassador)" == 1 ]]; then
            helm delete ambassador --purge
        fi
        for crd in $(kubectl get customresourcedefinitions | grep ambassador | awk '{ print $1  }'); do
	    echo delelting ambassador customresourcedefinitions...
            kubectl delete customresourcedefinition $crd
        done
    }
    dashboard () {
	wget --timestamping --quiet https://metriton.datawire.io/downloads/darwin/edgectl
	chmod +x edgectl
        endpoint_ip=$(kubectl \
                          get svc -n $NAMESPACE \
                          -o=jsonpath="{.items[?(@.metadata.name=='ambassador')].status.loadBalancer.ingress[0].ip}")
        ./edgectl login --namespace=$NAMESPACE $endpoint_ip
    }
    $*
}
#############################################################
##
##  Manage the S3 object store.
##
#############################################################
minio () {
    up () {
	echo installing minio...
        if [ "$(helm list | grep -c minio)" == 1 ]; then
            echo == WARNING ==: A minio release is already installed.
        else
            helm install \
                 --set accessKey=$minio_access_key \
                 --set secretKey=$minio_secret_key \
		 --set persistence.existingClaim=blackbalsam-jhub-nfs-pvc \
		 --set persistence.subPath=minio \
                 --name minio \
                 --namespace $NAMESPACE \
                 stable/minio
        fi
    }
    down () {
	echo uninstalling minio...
        if [[ "$(helm ls | grep -v NAME | awk '{ print $1 }' | grep -c minio)" == 1 ]]; then
            helm delete --purge minio
        fi
    }
    $*
}
#############################################################
##
##  Manage the memory cache data fabric.
##
#############################################################
alluxio () {
    up () {
	echo installing alluxio...
        echo "Configuring and starting alluxio..."
        export ALLUXIO_MASTER_HOST=alluxio-master-0
        export ALLUXIO_WORKER_HOST=alluxio-worker
        export MINIO_BUCKET=covid-19
        export MINIO_HOST=minio
        export MINIO_PORT=9000
        export MINIO_ACCESS_KEY=$minio_access_key
        export MINIO_SECRET_KEY=$minio_secret_key
        export alluxio_conf="./tmp/alluxio-k8s/singleMaster-localJournal/alluxio-configmap.yaml"

	echo copying alluxio config templates...
	mkdir -p tmp
	cp -r alluxio-k8s ./tmp

	envsubst < ${alluxio_conf}.template > $alluxio_conf
        echo "  configured. creating kubernetes artifacts."
        kubectl apply \
		--namespace $NAMESPACE \
		--recursive=true \
		-f ./tmp/alluxio-k8s
	rm -rf ./tmp/alluxio-k8s	
    }
    down () {
        echo "uninstalling alluxio..."
        kubectl delete \
		--ignore-not-found=true \
		--namespace $NAMESPACE \
		--recursive=true \
		-f alluxio-k8s
    }
    restart () {
        down
        up
    }
    $*
}
#############################################################
##
## Manage the Neo4J database.
##
#############################################################
neo4j () {
    up () {
#	config=$ETC/neo4j/neo4j-deployment.yaml
#	cp $config.template 
#	yaml_set_val spec.template.spec.containers[0].env.valueFrom.secretKeyRef. $neo4j_password $config
	kubectl --namespace $NAMESPACE apply -f etc/neo4j
    }
    down () {
	kubectl --namespace $NAMESPACE delete -f etc/neo4j
    }
    restart () {
	down
	up
    }
    $*
}
#############################################################
##
## Manage the data corpus this cluster provides
##
#############################################################
data () {
    up () {
	# Create the updater.
	kubectl --namespace $NAMESPACE apply -f etc/data/updater
    }
    down () {
	# Delete the udpater.
	kubectl --namespace $NAMESPACE delete -f etc/data/updater
    }
    run () {
	# Run a refresh job now.
	kubectl --namespace $NAMESPACE create job --from=cronjob/update-data-set update-data
    }
    stop () {
	# Stop the running refresh job.
	kubectl --namespace $NAMESPACE delete job/update-data
    }
    $*
}
#############################################################
##
##  Manage the system as a whole.
##
#############################################################
SYSTEMS="secrets minio alluxio neo4j proxy hub"
up () {
    echo installing blackbalsam...
    for system in $SYSTEMS; do
	echo "  --installing $system"
        $system up
    done
}
down () {
    echo uninstalling blackbalsam...
    reversed="$(echo $SYSTEMS | awk '{ for (i=NF; i>1; i--) printf("%s ",$i); print $1; }')"
    for system in $reversed; do
        $system down
    done
    kubectl delete --ignore-not-found=true namespace $NAMESPACE
}
restart () {
    echo "restarting blackbalsam"
    echo "   bringing the system down..."
    down
    echo "   bringing the system up..."
    up
}
status () {
    for kind in deployment pod service pvc pv; do
        message=$( echo $kind | awk '{ print toupper($0) }' )
        echo $message
        kubectl get -n $NAMESPACE $kind 2>&1 | sed "s,^,   ,g"
    done
}
nodes () {
    kubectl describe nodes
}
#############################################################
##
##  Initialize.
##
#############################################################
init () {
    # Require an init file.
    if [ ! -f $HOME/.blackbalsam ]; then
        echo $HOME/.blackbalsam must exist and contain a variable called jupyterhub_secret_token
        exit 1
    fi
    source $HOME/.blackbalsam

    tiller_status=$(kubectl \
			get deployment -n kube-system \
			-o=jsonpath="{.items[?(@.metadata.labels.name=='tiller')].metadata.labels.name}" | \
			grep -c tiller)

    if [ $tiller_status -eq 1 ]; then
	return 
    fi
    echo installing tiller...
    mkdir -p $DIST

    wget --timestamping --quiet --directory-prefix=$DIST $helm_url
    if [ ! -d $DIST/darwin-amd64 ]; then
        pushd $DIST
        tar xvzf $helm_dist
        popd
    fi
    if [ "$(kubectl get serviceaccounts -n kube-system | grep -c tiller)" == 0 ]; then
        kubectl --namespace kube-system create serviceaccount tiller
    fi
    if [ "$(kubectl get clusterrolebinding | grep -c tiller)" == 0 ]; then
        kubectl create clusterrolebinding tiller --clusterrole cluster-admin --serviceaccount=kube-system:tiller
    fi
    helm init --service-account tiller --history-max 100 --wait
    kubectl patch deployment tiller-deploy \
            --namespace=kube-system --type=json \
            --patch='[{"op": "add", "path": "/spec/template/spec/containers/0/command", "value": ["/tiller", "--listen=localhost:44134"]}]'

    helm version
    helm repo add jupyterhub https://jupyterhub.github.io/helm-chart/
    helm repo update
}

#############################################################
##
##  Help.
##
#############################################################
help () {
    help_message="\
$0 is a data science cluster architecture.

User Experience Services:
  hub   \tConfigure, install, and uninstall JupyterHub notebook server.
  hub up\tStart JupyterHub. Configure Ambassador, storage, etc. Also used to update the configuration.
  hub down\tStop JupyterHub.
  hub restart\tRestart the JupyterHub service.

Storage Services:
  alluxio\tManage cluster deployment of Alluxio services.
  alluxio up\tInstall Alluxio and distributed workers.
  alluxio down\tDelete the Alluxio network.
  minio \tManage cluster deployment of the Minio S3 system.
  minio up\tInstall Minio. Creates a service called 'minio'.
  minio down\tDelete Minio.

Proxy Services:
  proxy \tManage the programmable Ambassador edge proxy.

Data Services:
  data  \tManage the data collection for this cluster.
  data up\tInstall the periodic data update task.
  data down\tDelete the periodic data update task.
  data run\tRun the periodic data update task now.
  data stop\tStop the running data update task if one exists

Secrets:
  secrets\tManage secrets
  secrets up\tCreate secrets based on environment conifguration.
  secrets down\tDelete created secrets.
  secrets status\tShow status of secrets.

Overall Management:
  up    \tExecute configurations and start all services.
  down  \tStop all cluster components and services.
  restart\tStop and start all system components.
  status\tReport on Kubernetes components of the system in detail.
  nodes \tDisplay detailed usage and status for cluster nodes.

Other Commands:
  help  \tShow this message.

"
    printf "$help_message"
}

init

$*

exit 0
